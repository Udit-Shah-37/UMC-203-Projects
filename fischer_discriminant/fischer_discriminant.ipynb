{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.join(os.path.dirname(os.path.abspath('__file__')), 'oracle'))\n",
    "import oracle\n",
    "\n",
    "data = oracle.q1_fish_train_test_data(23475)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def filter_class_data(data, labels, class_label):\n",
    "    \"\"\"Filters and flattens the images belonging to a specific class.\"\"\"\n",
    "    class_images = data[labels == class_label]  \n",
    "    return 255*class_images.reshape(class_images.shape[0], -1) \n",
    "    \n",
    "\n",
    "def sample_random_subset(class_data, n):\n",
    "    \"\"\"Selects a random subset of n samples from the given class data.\"\"\"\n",
    "    j = np.random.choice(class_data.shape[0], n, replace=False)\n",
    "    return class_data[j]\n",
    "\n",
    "def compute_mean_vector(data_subset):\n",
    "    \"\"\"Computes the mean vector of the given data subset.\"\"\"\n",
    "    return np.mean(data_subset, axis=0)\n",
    "\n",
    "def compute_covariance_matrix(data_subset):\n",
    "    \"\"\"Computes the covariance matrix of the given data subset.\"\"\"\n",
    "    return np.cov(data_subset, rowvar=False)\n",
    "\n",
    "def compute_norms(mean_vector, covariance_matrix):\n",
    "    \"\"\"Computes the L2 norm of the mean vector and the Frobenius norm of the covariance matrix.\"\"\"\n",
    "    mean_norm = np.linalg.norm(mean_vector)  # Default is L2 norm\n",
    "    cov_norm = np.linalg.norm(covariance_matrix, 'fro')  # Frobenius norm\n",
    "    return mean_norm, cov_norm\n",
    "\n",
    "def compute_statistics_for_sample(class_data, n):\n",
    "    \"\"\"Computes mean and covariance norms for a random sample of size n.\"\"\"\n",
    "    subset = sample_random_subset(class_data, n)\n",
    "    mean_vector = compute_mean_vector(subset)\n",
    "    covariance_matrix = compute_covariance_matrix(subset)\n",
    "    return compute_norms(mean_vector, covariance_matrix)\n",
    "\n",
    "def compute_statistics(data, labels, class_label, sample_sizes):\n",
    "    \"\"\"Computes the L2 norm of the mean vector and the Frobenius norm of the covariance matrix for different sample sizes.\"\"\"\n",
    "    class_data = filter_class_data(data, labels, class_label)\n",
    "    mean_norms, cov_norms = [], []\n",
    "\n",
    "    for n in sample_sizes:\n",
    "        mean_norm, cov_norm = compute_statistics_for_sample(class_data, n)\n",
    "        mean_norms.append(mean_norm)\n",
    "        cov_norms.append(cov_norm)\n",
    "    \n",
    "    return mean_norms, cov_norms\n",
    "\n",
    "# Extract data and labels\n",
    "train_data = np.array(data[1])  \n",
    "train_labels = np.array(data[2])\n",
    "\n",
    "# Define sample sizes to test\n",
    "sample_sizes = [50, 100, 500, 1000, 2000, 4000]\n",
    "\n",
    "# Store norms for each class\n",
    "class_norms = {}\n",
    "for class_label in range(4):\n",
    "    mean_norms, cov_norms = compute_statistics(train_data, train_labels, class_label, sample_sizes)\n",
    "    class_norms[class_label] = (mean_norms, cov_norms)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "for class_label, (mean_norms, cov_norms) in class_norms.items():\n",
    "    plt.plot(sample_sizes, mean_norms, marker='o', linestyle='-', label=f'Class {class_label} Mean L2 Norm')\n",
    "plt.xlabel('Number of Samples')\n",
    "plt.ylabel('L2 Norm of Mean Vector')\n",
    "plt.title('L2 Norm of Mean Vector vs Sample Size')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "for class_label, (mean_norms, cov_norms) in class_norms.items():\n",
    "    plt.plot(sample_sizes, cov_norms, marker='o', linestyle='-', label=f'Class {class_label} Covariance Frobenius Norm')\n",
    "plt.xlabel('Number of Samples')\n",
    "plt.ylabel('Frobenius Norm of Covariance Matrix')\n",
    "plt.title('Frobenius Norm of Covariance Matrix vs Sample Size')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm  # For progress tracking\n",
    "from matplotlib.pylab import det\n",
    "import pickle  # For saving intermediate results\n",
    "\n",
    "# Load data\n",
    "data = oracle.q1_fish_train_test_data(23475)\n",
    "X = np.array(data[1])\n",
    "Y = np.array(data[2]) \n",
    "\n",
    "# Flatten each image to a 1D vector\n",
    "X = X.reshape(X.shape[0], -1)  # Shape: (N, 3072)\n",
    "\n",
    "# Define subset sizes\n",
    "subset_sizes = [2500, 3500, 4000, 4500, 5000]\n",
    "\n",
    "\n",
    "# Storage for results\n",
    "scatter_matrices = {}  # Store S_W and S_B\n",
    "objective_values = {n: [] for n in subset_sizes}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def sample(X, y, n):\n",
    "    \"\"\"Randomly selects 'n' samples per class and returns a subset.\"\"\"\n",
    "    j = []\n",
    "    for c in range(4):\n",
    "        j.extend(np.random.choice(np.where(y == c)[0], n, replace=False))\n",
    "    j = np.array(j)\n",
    "    return X[j], y[j]\n",
    "\n",
    "def class_means(X, y):\n",
    "    \"\"\"Computes class-wise mean vectors.\"\"\"\n",
    "    return {c: np.mean(X[y == c], axis=0) for c in range(4)}\n",
    "\n",
    "def scatter_matrices(X, y, class_means):\n",
    "    \"\"\"Computes within-class and between-class scatter matrices.\"\"\"\n",
    "    overall_mean = np.mean(X, axis=0)\n",
    "    S_W = np.zeros((X.shape[1], X.shape[1]))  \n",
    "    S_B = np.zeros((X.shape[1], X.shape[1]))\n",
    "\n",
    "    for c in range(4):\n",
    "        X_class = X[y == c]\n",
    "        mean_diff = class_means[c] - overall_mean\n",
    "        S_B += len(X_class) * np.linalg.matmul(mean_diff, mean_diff)\n",
    "\n",
    "        for x in X_class:\n",
    "            mean_diff = x - class_means[c]\n",
    "            S_W += np.matmul(mean_diff, mean_diff)\n",
    "    \n",
    "    return S_W, S_B\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in tqdm(subset_sizes, desc=\"Processing subset sizes\"):\n",
    "    scatter_results = {}  # Renamed dictionary variable\n",
    "\n",
    "    for n in tqdm(subset_sizes, desc=\"Processing sample sizes\"):\n",
    "        scatter_results[n] = []\n",
    "        X_subset, y_subset = sample(X, Y, n)\n",
    "        means_dict = class_means(X_subset, y_subset)\n",
    "        S_W, S_B = scatter_matrices(X_subset, y_subset, means_dict)  # Function call remains unchanged\n",
    "        scatter_results[n].append((S_W, S_B))\n",
    "    \n",
    "        # Print message after each iteration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def projection(S_W, S_B):\n",
    "    \"\"\"Computes the FLD projection matrix and objective function value.\"\"\"\n",
    "    eigvals, eigvecs = np.linalg.eig(np.linalg.inv(S_W) @ S_B)\n",
    "\n",
    "    # Sort eigenvalues in descending order and select top 3 eigenvectors\n",
    "    sorted_j = np.argsort(eigvals)[::-1]\n",
    "    W = eigvecs[:, sorted_j[:3]]  \n",
    "\n",
    "    # Compute objective value\n",
    "    object_value = det(np.matmul(np.matmul(W.T, S_B), W)) / det(np.matmul(np.matmul(W.T, S_W), W))\n",
    "\n",
    "    return W, object_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in tqdm(subset_sizes, desc=\"Processing W for subset sizes\"):\n",
    "    for S_W, S_B in tqdm(scatter_matrices[n], desc=f\"Computing W for n={n}\", leave=False):\n",
    "        W, obj_value = projection(S_W, S_B)\n",
    "        objective_values[n].append(obj_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5000  # Only visualize the largest subset\n",
    "\n",
    "X_subset, y_subset = sample(X, Y, n)\n",
    "W, _ = projection(*scatter_matrices[n][0])  \n",
    "# Project data\n",
    "Y_projected = X_subset @ W  \n",
    "# 3D Scatter plot\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "for c in range(4):\n",
    "    ax.scatter(Y_projected[y_subset == c, 0], \n",
    "               Y_projected[y_subset == c, 1], \n",
    "               Y_projected[y_subset == c, 2], \n",
    "               label=f'Class {c}', alpha=0.6)\n",
    "\n",
    "ax.set_xlabel('FLD Component 1')\n",
    "ax.set_ylabel('FLD Component 2')\n",
    "ax.set_zlabel('FLD Component 3')\n",
    "ax.set_title(f'FLD Projection in 3D (n={n})')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
