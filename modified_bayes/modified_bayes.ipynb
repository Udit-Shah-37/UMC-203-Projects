{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load Data\n",
    "data = oracle.q2_train_test_emnist(23475, \"EMNIST/emnist-balanced-train.csv\", \"EMNIST/emnist-balanced-test.csv\")\n",
    "training_set, test_set = data[0], data[1]\n",
    "\n",
    "# Extract training data and labels\n",
    "training_label = training_set[:, 0]\n",
    "training_data = training_set[:, 1:]\n",
    "test_label = test_set[:, 0]\n",
    "test_data =  test_set[:, 1:]\n",
    "\n",
    "def avg(r):\n",
    "    \"\"\"Compute mean vector for a given dataset X.\"\"\"\n",
    "    return np.mean(r, axis=0)\n",
    "\n",
    "# Function to Compute Covariance Matrix\n",
    "def cov(r):\n",
    "    \"\"\"Compute covariance matrix using the given mean.\"\"\"    \n",
    "    return np.cov(r, rowvar=False) \n",
    "\n",
    " #Separate Data by Class\n",
    "training_class0 = training_data[training_label == 9]\n",
    "training_class1 = training_data[training_label == 20]\n",
    "\n",
    "\n",
    "# Compute Mean & Covariance for Each Class\n",
    "avg_class0 = avg(training_class0)\n",
    "avg_class1 = avg(training_class1)\n",
    "\n",
    "cov_class0 = cov(training_class0)\n",
    "cov_class1 = cov(training_class1)\n",
    "\n",
    "\n",
    "modified_cov_class0 = cov_class0 + (10**(-7)) * np.identity(cov_class0.shape[0])\n",
    "modified_cov_class1 = cov_class1 + (10**(-7)) * np.identity(cov_class1.shape[0])\n",
    "\n",
    "\n",
    "# Inverses & Determinants for Efficiency\n",
    "C0_inv = np.linalg.pinv(cov_class0)\n",
    "C1_inv = np.linalg.pinv(cov_class1)\n",
    "\n",
    "cov_1_cov_0_inv = np.matmul(modified_cov_class1,np.linalg.pinv(modified_cov_class0))\n",
    "\n",
    "slogdetcov_1_cov_0_inv = np.linalg.slogdet(cov_1_cov_0_inv)[1]\n",
    "\n",
    "def log_posterior_ratio(r,p0,p1):\n",
    "    \"\"\"\n",
    "    Computes the log posterior ratio used for decision making\n",
    "    \"\"\"\n",
    "\n",
    "    dif_class0 = r - avg_class0\n",
    "    t_1 = -0.5 * np.matmul(np.matmul(dif_class0.T, C0_inv), dif_class0)\n",
    "    dif_class1 = r - avg_class1\n",
    "    t_2 = 0.5 * np.matmul(np.matmul(dif_class1.T, C1_inv), dif_class1)\n",
    "    t_3 = -np.log(p1) + np.log(p0)\n",
    "    t_4 = 0.5 * slogdetcov_1_cov_0_inv\n",
    "    return t_1 + t_2 +  t_3 + t_4\n",
    "   \n",
    "#Modified Bayes Classifier with Reject Option\n",
    "def modified_bayes_classifier(r, epsilon):\n",
    "    \"\"\"\n",
    "    Classifies r using the Modified Bayes Classifier with reject option.\n",
    "    \"\"\"\n",
    "    p0 = 0.5  \n",
    "    p1 = 0.5\n",
    "    ratio = log_posterior_ratio(r,p0,p1)\n",
    "    \n",
    "    \n",
    "    if ratio >=  np.log((0.5 + epsilon) / (0.5 - epsilon)):\n",
    "        return 9\n",
    "    elif ratio <= np.log((0.5 - epsilon) / (0.5 + epsilon)):\n",
    "        return 20\n",
    "    else:\n",
    "        return \"reject\"\n",
    "    \n",
    "\n",
    "epsilon_values = [0.01, 0.1, 0.25, 0.4]\n",
    "misclassification_losses = []\n",
    "rejected_samples = []\n",
    "\n",
    "for epsilon in epsilon_values:\n",
    "    rejected = 0\n",
    "    misclassified = 0\n",
    "    classified = 0\n",
    "    \n",
    "    for i in range(len(test_data)):\n",
    "        x = test_data[i]\n",
    "        prediction = modified_bayes_classifier(x, epsilon)\n",
    "        \n",
    "        if prediction == \"reject\":\n",
    "            rejected += 1\n",
    "            \n",
    "        else:\n",
    "            classified+= 1\n",
    "            if prediction != test_label[i]:\n",
    "                misclassified+= 1\n",
    "                \n",
    "    \n",
    "    if classified > 0 :\n",
    "\n",
    "        misclassification_loss = misclassified / classified\n",
    "    else:\n",
    "        misclassification_loss = 0\n",
    "    misclassification_losses.append(misclassification_loss)\n",
    "    rejected_samples.append(rejected)\n",
    "\n",
    "for i, epsilon in enumerate(epsilon_values):\n",
    "    print(f\"Epsilon: {epsilon}, Misclassification Loss: {misclassification_losses[i]:.4f}, Rejected Samples: {rejected_samples[i]}, Misclassified Samples: {misclassification_losses[i]*classified}\")\n",
    "\n",
    "\n",
    "#Plot Misclassification Loss vs Epsilon\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(epsilon_values, misclassification_losses, marker='o', linestyle='-', color='b', label=\"Misclassification Loss\")\n",
    "plt.xlabel(\"Epsilon (ϵ)\")\n",
    "plt.ylabel(\"Misclassification Loss\")\n",
    "plt.title(\"Effect of ϵ on Misclassification Loss\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load Data (assuming oracle.q2_train_test_emnist is defined)\n",
    "data = oracle.q2_train_test_emnist(23475, \"EMNIST/emnist-balanced-train.csv\", \"EMNIST/emnist-balanced-test.csv\")\n",
    "training_set, test_set = data[0], data[1]\n",
    "\n",
    "# Extract training data and labels\n",
    "training_label = training_set[:, 0]\n",
    "training_data = training_set[:, 1:]\n",
    "test_label = test_set[:, 0]\n",
    "test_data = test_set[:, 1:]\n",
    "\n",
    "# Separate data by class (class0: label 9, class1: label 20)\n",
    "training_class0_all = training_data[training_label == 9]\n",
    "training_class1_all = training_data[training_label == 20]\n",
    "\n",
    "# Helper functions\n",
    "def compute_stats(data_subset):\n",
    "    \"\"\"Compute mean, covariance, modified covariance, and inverse covariance.\"\"\"\n",
    "    avg_vec = np.mean(data_subset, axis=0)\n",
    "    cov_mat = np.cov(data_subset, rowvar=False)\n",
    "    mod_cov_mat = cov_mat + (10**(-7)) * np.identity(cov_mat.shape[0])  # Stability adjustment\n",
    "    inv_cov = np.linalg.pinv(cov_mat)  # Use pseudo-inverse for numerical stability\n",
    "    return avg_vec, cov_mat, mod_cov_mat, inv_cov\n",
    "\n",
    "def log_posterior_ratio(x, avg0, avg1, inv_cov0, inv_cov1, slogdet_cov_ratio, p0, p1):\n",
    "    \"\"\"Compute the log posterior ratio for classification.\"\"\"\n",
    "    dif0 = x - avg0\n",
    "    t1 = -0.5 * np.dot(np.dot(dif0.T, inv_cov0), dif0)\n",
    "    dif1 = x - avg1\n",
    "    t2 = 0.5 * np.dot(np.dot(dif1.T, inv_cov1), dif1)\n",
    "    t3 = -np.log(p1) + np.log(p0)\n",
    "    t4 = 0.5 * slogdet_cov_ratio\n",
    "    return t1 + t2 + t3 + t4\n",
    "\n",
    "def modified_bayes_classifier(x, avg0, avg1, inv_cov0, inv_cov1, slogdet_cov_ratio, p0, p1, epsilon):\n",
    "    \"\"\"Classify x using the modified Bayesian classifier.\"\"\"\n",
    "    ratio = log_posterior_ratio(x, avg0, avg1, inv_cov0, inv_cov1, slogdet_cov_ratio, p0, p1) \n",
    "    if ratio >= np.log((0.5 + epsilon) / (0.5 - epsilon)):\n",
    "        return 9\n",
    "    elif ratio <= np.log((0.5 - epsilon) / (0.5 + epsilon)):\n",
    "        return 20\n",
    "    else:\n",
    "        return \"reject\"\n",
    "\n",
    "# Experiment configurations\n",
    "experiments = [\n",
    "    {\"n_class0\": 2400, \"n_class1\": 1600, \"p0\": 0.6,  \"p1\": 0.4},\n",
    "    {\"n_class0\": 2400, \"n_class1\": 600,  \"p0\": 0.8,  \"p1\": 0.2},\n",
    "    {\"n_class0\": 2400, \"n_class1\": 267,  \"p0\": 0.9,  \"p1\": 0.1},\n",
    "    {\"n_class0\": 2400, \"n_class1\": 24,   \"p0\": 0.99, \"p1\": 0.01}\n",
    "]\n",
    "\n",
    "epsilon_values = [0.1, 0.25, 0.4]  # Epsilon values\n",
    "\n",
    "# Store results for plotting\n",
    "misclassification_results = []\n",
    "\n",
    "# Loop over experiments\n",
    "for exp in experiments:\n",
    "    # Select class 0 samples\n",
    "    train_class0 = training_class0_all[:exp[\"n_class0\"]]\n",
    "    \n",
    "    # Select class 1 samples randomly\n",
    "    j = np.random.choice(len(training_class1_all), size=exp[\"n_class1\"], replace=False)\n",
    "    train_class1 = training_class1_all[j]\n",
    "    \n",
    "    # Compute statistics for each class\n",
    "    avg0, cov0, mod_cov0, inv_cov0 = compute_stats(train_class0)\n",
    "    avg1, cov1, mod_cov1, inv_cov1 = compute_stats(train_class1)\n",
    "    \n",
    "    # Compute determinant ratio term for log ratio computation\n",
    "    cov_ratio = np.matmul(mod_cov1, np.linalg.pinv(mod_cov0))\n",
    "    slogdet_cov_ratio = np.linalg.slogdet(cov_ratio)[1]\n",
    "    \n",
    "    # Store misclassification errors for this experiment\n",
    "    misclassification_errors = []\n",
    "\n",
    "    # Classify test data for each epsilon\n",
    "    for epsilon in epsilon_values:\n",
    "        misclassified = 0\n",
    "        classified = 0\n",
    "        \n",
    "        for i in range(len(test_data)):\n",
    "            x = test_data[i]\n",
    "            pred = modified_bayes_classifier(x, avg0, avg1, inv_cov0, inv_cov1, slogdet_cov_ratio, exp[\"p0\"], exp[\"p1\"], epsilon)\n",
    "            \n",
    "            if pred != \"reject\":\n",
    "                classified += 1\n",
    "                if pred != test_label[i]:\n",
    "                    misclassified += 1\n",
    "        \n",
    "        # Compute misclassification loss\n",
    "        misclassification_loss = misclassified / classified if classified > 0 else 0\n",
    "        misclassification_errors.append(misclassification_loss)\n",
    "        \n",
    "        print(f\"Experiment {exp['p0']} vs {exp['p1']} | Epsilon: {epsilon} | Misclassification Loss: {misclassification_loss:.4f}\")\n",
    "\n",
    "    misclassification_results.append(misclassification_errors)\n",
    "\n",
    "# **Plot all experiments on a single graph**\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Experiment labels for legend\n",
    "exp_labels = [f\"p0={exp['p0']}, p1={exp['p1']}\" for exp in experiments]\n",
    "\n",
    "# Plot each experiment\n",
    "for i, misclassification_errors in enumerate(misclassification_results):\n",
    "    plt.plot(epsilon_values, misclassification_errors, marker='o', label=exp_labels[i])\n",
    "\n",
    "plt.xlabel(\"Epsilon\")\n",
    "plt.ylabel(\"Misclassification Loss\")\n",
    "plt.title(\"Misclassification Loss vs. Epsilon for Different Splits\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "data = oracle.q2_train_test_emnist(23475, \"EMNIST/emnist-balanced-train.csv\", \"EMNIST/emnist-balanced-test.csv\")\n",
    "training_set, _ = data[0], data[1]\n",
    "\n",
    "training_label = training_set[:, 0]\n",
    "training_data = training_set[:, 1:]\n",
    "\n",
    "def avg(r):\n",
    "    \"\"\"Compute mean vector for data r.\"\"\"\n",
    "    return np.mean(r, axis=0)\n",
    "\n",
    "def cov(r):\n",
    "    \"\"\"Compute covariance matrix for data r.\"\"\"\n",
    "    return np.cov(r, rowvar=False)\n",
    "\n",
    "\n",
    "K = 5\n",
    "epsilon = 0.25\n",
    "kf = KFold(n_splits=K, shuffle=True, random_state=42)\n",
    "\n",
    "# To store metrics for each fold\n",
    "fold_metrics = []\n",
    "\n",
    "fold = 1\n",
    "for train_idx, val_idx in kf.split(training_data):\n",
    "    # Split into training and validation sets for this fold\n",
    "    X_train = training_data[train_idx]\n",
    "    y_train = training_label[train_idx]\n",
    "    X_val = training_data[val_idx]\n",
    "    y_val = training_label[val_idx]\n",
    "    \n",
    "  \n",
    "    train_class0 = X_train[y_train == 9]\n",
    "    train_class1 = X_train[y_train == 20]\n",
    "    \n",
    "    # If either class is missing in this fold, skip it\n",
    "    if len(train_class0) == 0 or len(train_class1) == 0:\n",
    "        continue\n",
    "\n",
    "    avg_class0 = avg(train_class0)\n",
    "    avg_class1 = avg(train_class1)\n",
    "    \n",
    "    cov_class0 = cov(train_class0)\n",
    "    cov_class1 = cov(train_class1)\n",
    "    \n",
    "    # Regularize covariance matrices slightly for numerical stability\n",
    "    modified_cov_class0 = cov_class0 + (10**(-7)) * np.identity(cov_class0.shape[0])\n",
    "    modified_cov_class1 = cov_class1 + (10**(-7)) * np.identity(cov_class1.shape[0])\n",
    "    \n",
    "    # Compute pseudo-inverses of the original covariance matrices\n",
    "    C0_inv = np.linalg.pinv(cov_class0)\n",
    "    C1_inv = np.linalg.pinv(cov_class1)\n",
    "    \n",
    "    # Compute a determinant term based on the modified covariances\n",
    "    cov_1_cov_0_inv = np.matmul(modified_cov_class1, np.linalg.pinv(modified_cov_class0))\n",
    "    slogdetcov_1_cov_0_inv = np.linalg.slogdet(cov_1_cov_0_inv)[1]\n",
    "    \n",
    "    # For this experiment, assume equal priors\n",
    "    p0_val = 0.5\n",
    "    p1_val = 0.5\n",
    "    \n",
    "\n",
    "    def fold_log_posterior_ratio(r, p0, p1):\n",
    "        \"\"\"\n",
    "        Computes the log posterior ratio for sample r.\n",
    "        \"\"\"\n",
    "        dif_class0 = r - avg_class0\n",
    "        t_1 = -0.5 * np.matmul(np.matmul(dif_class0.T, C0_inv), dif_class0)\n",
    "        \n",
    "        dif_class1 = r - avg_class1\n",
    "        t_2 = 0.5 * np.matmul(np.matmul(dif_class1.T, C1_inv), dif_class1)\n",
    "        \n",
    "        t_3 = -np.log(p1) + np.log(p0)\n",
    "        t_4 = 0.5 * slogdetcov_1_cov_0_inv\n",
    "        return t_1 + t_2 + t_3 + t_4\n",
    "\n",
    "    def fold_modified_bayes_classifier(r, epsilon):\n",
    "        \"\"\"\n",
    "        Classifies sample r using the Modified Bayes Classifier with reject option.\n",
    "        Returns 9 if the ratio is high, 20 if low, or \"reject\" otherwise.\n",
    "        \"\"\"\n",
    "        ratio = fold_log_posterior_ratio(r, p0_val, p1_val)\n",
    "        threshold_high = np.log((0.5 + epsilon) / (0.5 - epsilon))\n",
    "        threshold_low  = np.log((0.5 - epsilon) / (0.5 + epsilon))\n",
    "        \n",
    "        if ratio >= threshold_high:\n",
    "            return 9\n",
    "        elif ratio <= threshold_low:\n",
    "            return 20\n",
    "        else:\n",
    "            return \"reject\"\n",
    "    \n",
    "   \n",
    "    true_labels = []       # true labels for classified samples\n",
    "    predicted_labels = []  # classifier predictions (9 or 20)\n",
    "    num_rejected = 0       # count rejected samples\n",
    "    \n",
    "    for i in range(len(X_val)):\n",
    "        x = X_val[i]\n",
    "        pred = fold_modified_bayes_classifier(x, epsilon)\n",
    "        if pred == \"reject\":\n",
    "            num_rejected += 1\n",
    "        else:\n",
    "            true_labels.append(y_val[i])\n",
    "            predicted_labels.append(pred)\n",
    "    \n",
    "\n",
    "    TP = 0\n",
    "    TN = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    for i in range(len(true_labels)):\n",
    "        t = true_labels[i]\n",
    "        p = predicted_labels[i]\n",
    "        if t == 20 and p == 20:\n",
    "            TP += 1\n",
    "        elif t == 9 and p == 9:\n",
    "            TN += 1\n",
    "        elif t == 9 and p == 20:\n",
    "            FP += 1\n",
    "        elif t == 20 and p == 9:\n",
    "            FN += 1\n",
    "    \n",
    "    # Compute performance metrics over the non-rejected samples\n",
    "    recall    = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "    accuracy  = (TP + TN) / len(true_labels) if len(true_labels) > 0 else 0\n",
    "    f1_score  = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "    # Store metrics for this fold\n",
    "    fold_metrics.append({\n",
    "        \"fold\": fold,\n",
    "        \"TP\": TP, \"TN\": TN, \"FP\": FP, \"FN\": FN,\n",
    "        \"recall\": recall,\n",
    "        \"precision\": precision,\n",
    "        \"accuracy\": accuracy,\n",
    "        \"f1_score\": f1_score,\n",
    "        \"num_rejected\": num_rejected,\n",
    "        \"num_classified\": len(true_labels)\n",
    "    })\n",
    "    \n",
    "    print(f\"Fold {fold} results:\")\n",
    "    print(f\"  Confusion Matrix: TP = {TP}, TN = {TN}, FP = {FP}, FN = {FN}\")\n",
    "    print(f\"  Recall:    {recall:.4f}\")\n",
    "    print(f\"  Precision: {precision:.4f}\")\n",
    "    print(f\"  Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"  F1 Score:  {f1_score:.4f}\")\n",
    "    print(f\"  Rejected Samples: {num_rejected}\")\n",
    "    print(f\"  Classified Samples: {len(true_labels)}\\n\")\n",
    "    \n",
    "    fold += 1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
